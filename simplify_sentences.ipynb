{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accepts a file of raw_data, simplifies each sentences according to process mentioned in paper\n",
    "\n",
    "from __future__ import unicode_literals\n",
    "import parserz\n",
    "import tokenizer\n",
    "from parserz.isc_parser import Parser\n",
    "from tokenizer import *\n",
    "import tokenizer.isc_tokenizer\n",
    "from tokenizer.isc_tokenizer import Tokenizer\n",
    "from isc_tagger import Tagger\n",
    "\n",
    "#positions of different args of the dependency parse \n",
    "index = 0\n",
    "lex_item = 1\n",
    "POS = 4\n",
    "parent = 6\n",
    "dep_rel = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#READING INPUT\n",
    "input_file = open(\"raw_data.txt\",\"r\")\n",
    "simplified_data = open(\"simplified_data.txt\",\"w\")\n",
    "#Sentence tokenize data \n",
    "tk = Tokenizer(lang='hin', split_sen = True)\n",
    "text_file = input_file.read()\n",
    "text_data = tk.tokenize(text_file)\n",
    "# print(text_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_information(sentence):\n",
    "    parser = Parser(lang='hin')\n",
    "    tree = parser.parse(sentence)\n",
    "    print('\\n'.join(['\\t'.join(node) for node in tree]))\n",
    "    #Finding the (verb) root\n",
    "    main_index = '0'\n",
    "    heads = {'0'}\n",
    "    for i in range(len(tree)):\n",
    "        row = tree[i]\n",
    "        if(row[parent]=='0' and row[dep_rel]=='main'):\n",
    "            main_index = row[index]\n",
    "    print(main_index)\n",
    "    heads.add(main_index)\n",
    "    #If we have a conjunct structure, there is a possibility of noun ellipsis. If we identify it, we simply truncate the sentence.\n",
    "    if(tree[int(main_index)-1][POS]=='CC'):\n",
    "        for i in range(len(tree)):\n",
    "            row = tree[i]\n",
    "            if(row[parent]==main_index and row[POS]=='VM'): #Find verb children - roots of S1 S2 subtrees\n",
    "                print(row)\n",
    "                nsubj = False\n",
    "                for j in range(len(tree)):\n",
    "                    if(tree[j][parent]==str(i+1) and tree[j][dep_rel]=='k1'): #Subject\n",
    "                        nsubj = True\n",
    "                if(nsubj):\n",
    "                    heads.add(tree[i][index]) #Add verb to heads to pick up its dependents\n",
    "                else:\n",
    "                    if(i>int(main_index)):\n",
    "                        heads.remove(main_index)\n",
    "                        new_sentence=[]\n",
    "                        for i in range(int(main_index)-1):\n",
    "                            new_sentence.append(tree[i][lex_item])\n",
    "                        if(tree[len(tree)-1][POS]=='SYM'):\n",
    "                            new_sentence.append(tree[len(tree)-1][lex_item])\n",
    "                        print(new_sentence)\n",
    "                        return(extract_information(new_sentence)) #Recursion on truncated sentence\n",
    "\n",
    "\n",
    "    #Finding the children of the root, as the heads of required phrases\n",
    "    acceptable_tags = {'NN','NNP','QC', 'PRP','PSP','VM', 'VAUX', 'JJ','CC', 'SYM'} \n",
    "    #excluding NLoc, which is adverbial, like 'ghar mein' \n",
    "    #including JJ, because it may be pof\n",
    "    #including QC, for नौ घर आए। etc. Technically we have an ellipsis\n",
    "    acceptable_rel = {'k1','k2','pof', 'k2p','k3','k4','k5','lwg__psp', 'lwg__vaux', 'lwg__vaux_cont', 'ccof', 'main', 'rsym'}\n",
    "    #These might not pick up compound verb formations: adding 'pof' to pick up noun parts of CV\n",
    "    for i in range(len(tree)):\n",
    "        row = tree[i]\n",
    "        if(row[parent]==main_index and row[POS] in acceptable_tags and row[dep_rel] in acceptable_rel):\n",
    "            heads.add(row[index])\n",
    "    print(\"Heads: \")\n",
    "    print(heads)\n",
    "    #Collecting correct dependents, like noun and pp arguments, of heads, and building a set of correct indices\n",
    "    indices = set()\n",
    "    for i in range(len(tree)):\n",
    "        row = tree[i]\n",
    "        if(row[parent] in heads and row[POS] in acceptable_tags and row[dep_rel] in acceptable_rel):\n",
    "            indices.add(i+1) #note that these are tree list indices: i = row index - 1\n",
    "    print(\"Collected indices: \")\n",
    "    print(indices)\n",
    "    #OPTIONAL: Going one further level down for safety\n",
    "    for i in range(len(tree)):\n",
    "        row = tree[i]\n",
    "        if((int)(row[parent]) in indices and row[POS] in acceptable_tags and row[dep_rel] in acceptable_rel):\n",
    "            indices.add(i+1)\n",
    "    #Building simplified sentence\n",
    "    simplified_sent = \"\"\n",
    "    for i in range(len(tree)):\n",
    "        if((i+1) in indices):\n",
    "            simplified_sent += tree[i][lex_item] + \" \"\n",
    "    if(tree[len(tree)-1][POS]=='SYM'):\n",
    "        simplified_sent += (tree[len(tree)-1][lex_item]) + \"\\n\"\n",
    "\n",
    "    print(\"Simplified sentences: \")\n",
    "    print(simplified_sent)\n",
    "    return(simplified_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tमहानगर\tमहानगर\tNNPC\tNNPC\t_\t2\tpof__cn\t_\t_\n",
      "2\tपालिका\tपालिका\tNNP\tNNP\t_\t21\tk7a\t_\t_\n",
      "3\tअंतर्गत\tअंतर्गत\tPSP\tPSP\t_\t2\tlwg__psp\t_\t_\n",
      "4\tदत्तात्रय\tदत्तात्रय\tNNPC\tNNPC\t_\t7\tpof__cn\t_\t_\n",
      "5\tनगर\tनगर\tNNPC\tNNPC\t_\t7\tpof__cn\t_\t_\n",
      "6\tमाध्यमिक\tमाध्यमिक\tNNPC\tNNPC\t_\t7\tpof__cn\t_\t_\n",
      "7\tस्कूल\tस्कूल\tNNP\tNNP\t_\t9\tr6\t_\t_\n",
      "8\tके\tके\tPSP\tPSP\t_\t7\tlwg__psp\t_\t_\n",
      "9\tविद्यार्थियों\tविद्यार्थियों\tNN\tNN\t_\t21\tk1\t_\t_\n",
      "10\tने\tने\tPSP\tPSP\t_\t9\tlwg__psp\t_\t_\n",
      "11\tकाल्पनिक\tकाल्पनिक\tJJ\tJJ\t_\t12\tnmod__adj\t_\t_\n",
      "12\tकिला\tकिला\tNN\tNN\t_\t16\tk2\t_\t_\n",
      "13\t'\t'\tSYM\tSYM\t_\t14\trsym\t_\t_\n",
      "14\tदत्तगढ़\tदत्तगढ़\tNNP\tNNP\t_\t16\tk2\t_\t_\n",
      "15\t'\t'\tSYM\tSYM\t_\t14\trsym\t_\t_\n",
      "16\tबनाकर\tबनाकर\tVM\tVM\t_\t21\tvmod\t_\t_\n",
      "17\tअपनी\tअपनी\tPRP\tPRP\t_\t18\tr6\t_\t_\n",
      "18\tकल्पनाशक्ति\tकल्पनाशक्ति\tNN\tNN\t_\t20\tr6-k2\t_\t_\n",
      "19\tका\tका\tPSP\tPSP\t_\t18\tlwg__psp\t_\t_\n",
      "20\tपरिचय\tपरिचय\tNN\tNN\t_\t21\tpof\t_\t_\n",
      "21\tदिया\tदिया\tVM\tVM\t_\t0\tmain\t_\t_\n",
      "22\t।\t।\tSYM\tSYM\t_\t21\trsym\t_\t_\n",
      "21\n",
      "Heads: \n",
      "{'0', '21', '9', '20', '22'}\n",
      "Collected indices: \n",
      "{9, 10, 20, 21, 22}\n",
      "Simplified sentences: \n",
      "विद्यार्थियों ने परिचय दिया । ।\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6645642d10d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#For each sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msimplified_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_information\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0msimplified_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Original:\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msimplified_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-0aab30dc009b>\u001b[0m in \u001b[0;36mextract_information\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_information\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#Finding the (verb) root\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Hindi-Verb-Prediction/parserz/isc_parser/parser/parser.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, beamwidth, lang, ud)\u001b[0m\n\u001b[1;32m     44\u001b[0m         }\n\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeamwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeamwidth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemplate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTemplate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mud\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mud\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mud\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'_ud'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mud\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'hin'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s/%s_parse%s.pkl'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mud\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Hindi-Verb-Prediction/parserz/isc_parser/parser/template.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pwindow, lang, ud)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mTemplate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTagger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mud\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mud\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mud\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         node = namedtuple('leaf', ('id', 'form', 'lemma', 'ctag', 'tag',\n\u001b[1;32m     20\u001b[0m                                    \u001b[0;34m'features'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'parent'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pparent'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'drel'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Hindi-Verb-Prediction/isc_tagger/tagger/tagger.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lang, ud, wx)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mud\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTagEmbedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwxp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwx\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'hin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mud\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'_ud'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mud\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'hin'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Hindi-Verb-Prediction/isc_tagger/embedder/embedder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, window, lang)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc3vm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordVec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_wordvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s/%s_c3.vec'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mEMBD_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb3vm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordVec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_wordvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s/%s_b3.vec'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mEMBD_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordVec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_wordvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s/%s_word.vec'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mEMBD_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[0-9٠-٩۰-۹]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunkt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'، ۔ ؟ ؛'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Hindi-Verb-Prediction/isc_tagger/embedder/embedder.py\u001b[0m in \u001b[0;36mload_wordvec\u001b[0;34m(self, fname, encoding, unicode_errors)\u001b[0m\n\u001b[1;32m     62\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mch\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb'\\n'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                         \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                 word = to_unicode(b''.join(word), encoding=encoding,\n\u001b[1;32m     66\u001b[0m                                   errors=unicode_errors)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#For each sentence\n",
    "for sentence in text_data:\n",
    "    simplified_sent = extract_information(sentence)\n",
    "    simplified_data.write(\"Original:\\n\")\n",
    "    simplified_data.write(\" \".join(sentence))\n",
    "    simplified_data.write(\"\\n\"+\"Simplified:\\n\"+ simplified_sent+\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
